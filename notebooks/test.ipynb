{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenar\\Documents\\GroundingDINO\\groundingdino\\models\\GroundingDINO\\ms_deform_attn.py:31: UserWarning: Failed to load custom C++ ops. Running on CPU mode Only!\n",
      "  warnings.warn(\"Failed to load custom C++ ops. Running on CPU mode Only!\")\n"
     ]
    }
   ],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "model = load_model(\"groundingdino/config/GroundingDINO_SwinB_cfg.py\", \"weights/groundingdino_swinb_cogcoor.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(IMAGE_PATH):\n",
    "    image_source, image = load_image(IMAGE_PATH)\n",
    "    \n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=TEXT_PROMPT,\n",
    "        box_threshold=BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "    \n",
    "    annotated_frame, bbs = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "    return bbs, image_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def calculate_angle(p1, p2):\n",
    "    \"\"\"Вычисляет угол между линией, соединяющей две точки, и вертикальной осью (ось Y).\"\"\"\n",
    "    delta_x = p2[0] - p1[0]\n",
    "    delta_y = p2[1] - p1[1]\n",
    "    angle_rad = math.atan2(delta_y, delta_x)\n",
    "    return 90 + math.degrees(angle_rad)\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"Поворачивает изображение на заданный угол без обрезки.\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Вычисляем диагональ изображения\n",
    "    diagonal = int(math.sqrt(width ** 2 + height ** 2))\n",
    "\n",
    "    # Создаем увеличенное изображение с размерами диагонали, чтобы избежать обрезки\n",
    "    enlarged_image = cv2.copyMakeBorder(image, (diagonal - height) // 2,\n",
    "                                        (diagonal - height) // 2,\n",
    "                                        (diagonal - width) // 2,\n",
    "                                        (diagonal - width) // 2,\n",
    "                                        cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    # Поворачиваем изображение\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((diagonal // 2, diagonal // 2), angle, 1)\n",
    "    rotated_image = cv2.warpAffine(enlarged_image, rotation_matrix, (diagonal, diagonal))\n",
    "\n",
    "    # Обрезка изображения до размера диагонали\n",
    "    y_offset = (rotated_image.shape[0] - diagonal) // 2\n",
    "    x_offset = (rotated_image.shape[1] - diagonal) // 2\n",
    "    cropped_image = rotated_image[y_offset:y_offset + diagonal, x_offset:x_offset + diagonal]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def correct_hand_orientation(image):\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            print(\"Рука не обнаружена\")\n",
    "            return image\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Получаем координаты точек 0 и 12\n",
    "            x0, y0 = hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y\n",
    "            x12, y12 = hand_landmarks.landmark[12].x, hand_landmarks.landmark[12].y\n",
    "\n",
    "            # Переводим в пиксели\n",
    "            height, width, _ = image.shape\n",
    "            p0 = (int(x0 * width), int(y0 * height))\n",
    "            p12 = (int(x12 * width), int(y12 * height))\n",
    "\n",
    "            # Вычисляем угол между линией (0, 12) и вертикальной осью\n",
    "            angle = calculate_angle(p0, p12)\n",
    "\n",
    "            # Поворачиваем изображение на полученный угол\n",
    "            corrected_image = rotate_image(image, angle)\n",
    "\n",
    "            return corrected_image\n",
    "\n",
    "    return image\n",
    "\n",
    "def correct_hand_orientation(image):\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            print(\"Рука не обнаружена\")\n",
    "            return image\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Получаем координаты точек 0 и 12\n",
    "            x0, y0 = hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y\n",
    "            x12, y12 = hand_landmarks.landmark[12].x, hand_landmarks.landmark[12].y\n",
    "\n",
    "            # Переводим в пиксели\n",
    "            height, width, _ = image.shape\n",
    "            p0 = (int(x0 * width), int(y0 * height))\n",
    "            p12 = (int(x12 * width), int(y12 * height))\n",
    "\n",
    "            # Вычисляем угол между линией (0, 12) и вертикальной осью\n",
    "            angle = calculate_angle(p0, p12)\n",
    "\n",
    "            # Поворачиваем изображение на полученный угол\n",
    "            corrected_image = rotate_image(image, angle)\n",
    "\n",
    "            return corrected_image\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_p0(image):\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            print(\"Рука не обнаружена\")\n",
    "            return None  # Возвращает None, если рука не обнаружена\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Получаем координаты точки 0\n",
    "            x0, y0 = hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y\n",
    "\n",
    "            # Переводим в пиксели\n",
    "            height, width, _ = image.shape\n",
    "            p0 = (int(x0 * width), int(y0 * height))\n",
    "\n",
    "            return p0  # Возвращаем только координаты p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'path-to-images-palm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m bb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bb]\n\u001b[0;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_source[bb[\u001b[38;5;241m1\u001b[39m]:bb[\u001b[38;5;241m3\u001b[39m],bb[\u001b[38;5;241m0\u001b[39m]:bb[\u001b[38;5;241m2\u001b[39m]], cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 12\u001b[0m corrected_image, p0 \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_hand_orientation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m corrected_image \u001b[38;5;241m=\u001b[39m corrected_image[\u001b[38;5;241m0\u001b[39m:p0[\u001b[38;5;241m1\u001b[39m], :]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp0\u001b[39m\u001b[38;5;124m'\u001b[39m, p0)\n",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m, in \u001b[0;36mcorrect_hand_orientation\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     65\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m corrected_image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     66\u001b[0m res \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(corrected_image)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Получаем координаты точек 0 и 12\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     x0, y0 \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mlandmark[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx, h\u001b[38;5;241m.\u001b[39mlandmark[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m     70\u001b[0m     p0 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(x0 \u001b[38;5;241m*\u001b[39m width), \u001b[38;5;28mint\u001b[39m(y0 \u001b[38;5;241m*\u001b[39m height))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "TEXT_PROMPT = \"palm\"\n",
    "BOX_TRESHOLD = 0.3\n",
    "TEXT_TRESHOLD = 0.3\n",
    "\n",
    "for img_name in os.listdir(dir_path):\n",
    "    IMAGE_PATH = dir_path + img_name\n",
    "    bbs, image_source = get_bb(IMAGE_PATH)\n",
    "    for i, bb in enumerate(bbs):\n",
    "        bb = [int(b) for b in bb]\n",
    "        image = cv2.cvtColor(image_source[bb[1]:bb[3],bb[0]:bb[2]], cv2.COLOR_BGR2RGB)\n",
    "        corrected_image = correct_hand_orientation(image)\n",
    "        cv2.imwrite('path-to-cropped-palm/' + str(i) + img_name, corrected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def make_square(image_path, output_path):\n",
    "    with Image.open(image_path) as im:\n",
    "        width, height = im.size\n",
    "\n",
    "        # Определяем, сколько пикселей нужно добавить\n",
    "        if width > height:\n",
    "            delta = width - height\n",
    "            padding = (0, delta // 2, 0, delta - delta // 2)\n",
    "        else:\n",
    "            delta = height - width\n",
    "            padding = (delta // 2, 0, delta - delta // 2, 0)\n",
    "\n",
    "        # Добавляем паддинг и создаем квадратное изображение\n",
    "        new_im = ImageOps.expand(im, padding)\n",
    "        new_im.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'path-to-cropped-palm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(folder):\n",
    "    make_square(folder + img, 'palm/' + img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
